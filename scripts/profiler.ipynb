{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glai/anaconda3/envs/subset/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18().cuda()\n",
    "inputs = torch.randn(5, 3, 224, 224).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True, with_stack=True) as prof:\n",
    "    with record_function(\"model_inferenceeeeeeeee\"): \n",
    "        for _ in range(5):\n",
    "            output = model(inputs)\n",
    "\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                model_inferenceeeeeeeee         9.15%       3.292ms        99.79%      35.886ms      35.886ms       0.000us         0.00%       4.268ms       4.268ms          -4 b        -268 b    -176.00 Kb    -109.74 Mb             1  \n",
      "                                           aten::conv2d         0.26%      92.000us        80.19%      28.839ms       1.442ms       0.000us         0.00%       3.184ms     159.200us           0 b           0 b      48.92 Mb           0 b            20  \n",
      "                                      aten::convolution         0.70%     250.000us        79.93%      28.747ms       1.437ms       0.000us         0.00%       3.184ms     159.200us           0 b           0 b      48.92 Mb           0 b            20  \n",
      "                                     aten::_convolution         0.45%     161.000us        79.24%      28.497ms       1.425ms       0.000us         0.00%       3.184ms     159.200us           0 b           0 b      48.92 Mb           0 b            20  \n",
      "                                aten::cudnn_convolution        12.00%       4.314ms        78.79%      28.336ms       1.417ms       3.184ms        74.60%       3.184ms     159.200us           0 b           0 b      48.92 Mb     -54.17 Mb            20  \n",
      "maxwell_scudnn_winograd_128x128_ldg1_ldg4_tile148n_n...         0.00%       0.000us         0.00%       0.000us       0.000us       1.836ms        43.02%       1.836ms     141.231us           0 b           0 b           0 b           0 b            13  \n",
      "                   maxwell_scudnn_128x128_relu_small_nn         0.00%       0.000us         0.00%       0.000us       0.000us     624.000us        14.62%     624.000us     208.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                       aten::batch_norm         0.15%      54.000us         5.52%       1.984ms      99.200us       0.000us         0.00%     605.000us      30.250us           0 b           0 b      48.27 Mb           0 b            20  \n",
      "                           aten::_batch_norm_impl_index         0.21%      75.000us         5.37%       1.930ms      96.500us       0.000us         0.00%     605.000us      30.250us           0 b           0 b      48.27 Mb           0 b            20  \n",
      "                                 aten::cudnn_batch_norm         2.39%     861.000us         5.16%       1.855ms      92.750us     605.000us        14.18%     605.000us      30.250us           0 b           0 b      48.27 Mb           0 b            20  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 35.963ms\n",
      "Self CUDA time total: 4.268ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof.export_stacks(\"./profiler_stacks.txt\", \"self_cuda_time_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize as flamegrpah\n",
    "\"\"\"\n",
    "cd Flamegraph\n",
    "./flamegraph.pl --title \"CUDA time\" --countname \"us.\" /Users/garylai/Dev/subset-active-learning/local_bucket/profiler_stacks.txt > perf_viz.svg\n",
    "open .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electra Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: sst/default\n",
      "Reusing dataset sst (/home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n",
      "100%|██████████| 3/3 [00:00<00:00, 750.90it/s]\n",
      "Downloading: 100%|██████████| 482/482 [00:00<00:00, 306kB/s]\n",
      "Downloading: 100%|██████████| 899k/899k [00:00<00:00, 2.92MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 1.85MB/s]\n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:00<00:00, 3.51MB/s]\n",
      "100%|██████████| 8544/8544 [00:02<00:00, 3618.59ex/s]\n",
      "100%|██████████| 1101/1101 [00:00<00:00, 3576.10ex/s]\n",
      "100%|██████████| 2210/2210 [00:00<00:00, 3749.55ex/s]\n",
      "100%|██████████| 8544/8544 [00:01<00:00, 6485.67ex/s]\n",
      "100%|██████████| 1101/1101 [00:00<00:00, 6663.57ex/s]\n",
      "100%|██████████| 2210/2210 [00:00<00:00, 6668.17ex/s]\n"
     ]
    }
   ],
   "source": [
    "from subset_active_learning.subset_selection import select, preprocess\n",
    "MODEL_CARD = \"roberta-large\"\n",
    "train_args = select.SubsetTrainingArguments(max_steps=1, model_card=MODEL_CARD)\n",
    "processed_ds = preprocess.preprocess_sst2(MODEL_CARD)\n",
    "subset_trainer = select.SubsetTrainer(params=train_args, valid_ds=processed_ds[\"validation\"].select(range(5)), test_ds=processed_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True, with_stack=True) as prof:\n",
    "    with record_function(\"electra\"): \n",
    "        subset_trainer.train(subset=processed_ds[\"train\"].select(range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: sst/default\n",
      "Reusing dataset sst (/home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n",
      "100%|██████████| 3/3 [00:00<00:00, 783.49it/s]\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-7b23d5d1250b3cef.arrow\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-6a94e7b0eb5aeeeb.arrow\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-f1806eefe95f0de4.arrow\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-e283858a38c31b48.arrow\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-39bfe2cb0f239a41.arrow\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-a9c205acb85f354d.arrow\n",
      "Loading cached shuffled indices for dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-a6c29e03970dd67c.arrow\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from typing import Any, Optional\n",
    "from pydantic import BaseModel, Extra, Field\n",
    "from transformers import TrainingArguments, AutoModel, AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
    "import numpy as np\n",
    "import json\n",
    "import datasets\n",
    "import wandb\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from subset_active_learning.subset_selection import select, preprocess\n",
    "\n",
    "\n",
    "N_RUNS = 20\n",
    "DB_PATH = \"/home/glai/dev/subset-active-learning/local_bucket/new_sst.db\"\n",
    "\n",
    "training_args = select.SubsetTrainingArguments()\n",
    "searching_args = select.SubsetSearcherArguments(seed=0, db_path=DB_PATH)\n",
    "\n",
    "processed_ds = preprocess.preprocess_sst2(training_args.model_card)\n",
    "\n",
    "subset_trainer = select.SubsetTrainer(\n",
    "    params=training_args, valid_ds=processed_ds[\"validation\"], test_ds=processed_ds[\"test\"]\n",
    ")\n",
    "\n",
    "data_pool = processed_ds[\"train\"].shuffle(seed=searching_args.seed).select(range(searching_args.data_pool_size))\n",
    "subset_searcher = select.SubsetSearcher(subset_trainer=subset_trainer, params=searching_args, data_pool=data_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### RUN 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgarylai\u001b[0m (\u001b[33mjohnny-gary\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/glai/dev/subset-active-learning/scripts/wandb/run-20220921_220136-3gysqpxe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny-gary/subset-search/runs/3gysqpxe\" target=\"_blank\">cosmic-planet-34</a></strong> to <a href=\"https://wandb.ai/johnny-gary/subset-search\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Acc: 0.55: 100%|██████████| 138/138 [00:03<00:00, 45.74it/s]00:43<13:40,  6.95it/s]\n",
      "Acc: 0.63: 100%|██████████| 138/138 [00:03<00:00, 42.36it/s]01:31<13:34,  6.63it/s]  \n",
      "Acc: 0.64: 100%|██████████| 138/138 [00:03<00:00, 41.94it/s]02:20<12:38,  6.72it/s]  \n",
      "Acc: 0.64: 100%|██████████| 138/138 [00:03<00:00, 42.50it/s][03:08<12:06,  6.61it/s] \n",
      "Acc: 0.64: 100%|██████████| 138/138 [00:03<00:00, 42.27it/s] [03:57<11:26,  6.56it/s] \n",
      "Acc: 0.64: 100%|██████████| 138/138 [00:02<00:00, 47.40it/s] [04:46<09:36,  7.28it/s]  \n",
      "Epoch: 138, Avg batch loss: 0.00:  30%|███       | 1800/6000 [04:49<11:14,  6.23it/s]\n",
      "Acc: 0.67: 100%|██████████| 277/277 [00:05<00:00, 49.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>data_pool_size</td><td>▁</td></tr><tr><td>loss</td><td>██████▇▇█▇▆▅▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>optimal_subset_size</td><td>▁</td></tr><tr><td>sst2_test:accuracy</td><td>▁</td></tr><tr><td>sst:val_acc</td><td>▁▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>data_pool_size</td><td>1000</td></tr><tr><td>indices</td><td>[167, 331, 255, 734,...</td></tr><tr><td>loss</td><td>0.00352</td></tr><tr><td>model_card</td><td>google/electra-small...</td></tr><tr><td>optimal_subset_size</td><td>100</td></tr><tr><td>sst2_test:accuracy</td><td>0.66787</td></tr><tr><td>sst:val_acc</td><td>0.64214</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cosmic-planet-34</strong>: <a href=\"https://wandb.ai/johnny-gary/subset-search/runs/3gysqpxe\" target=\"_blank\">https://wandb.ai/johnny-gary/subset-search/runs/3gysqpxe</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220921_220136-3gysqpxe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with profile(activities=[\n",
    "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"subset_search\"):\n",
    "        subset_searcher.search(n_runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.14%       1.890ms       100.00%        1.318s        1.318s       0.000us         0.00%       4.334ms       4.334ms             1  \n",
      "                                           aten::conv2d         0.00%      65.000us        99.52%        1.312s      65.593ms       0.000us         0.00%       3.213ms     160.650us            20  \n",
      "                                      aten::convolution         0.01%     185.000us        99.51%        1.312s      65.589ms       0.000us         0.00%       3.213ms     160.650us            20  \n",
      "                                     aten::_convolution         0.01%     124.000us        99.50%        1.312s      65.580ms       0.000us         0.00%       3.213ms     160.650us            20  \n",
      "                                aten::cudnn_convolution         0.45%       5.949ms        99.49%        1.311s      65.574ms       3.213ms        74.13%       3.213ms     160.650us            20  \n",
      "                                       cudaLaunchKernel        79.61%        1.049s        79.61%        1.049s       9.628ms       0.000us         0.00%       0.000us       0.000us           109  \n",
      "                                               cudaFree        19.29%     254.317ms        19.29%     254.317ms      36.331ms       0.000us         0.00%       0.000us       0.000us             7  \n",
      "                                       aten::batch_norm         0.00%      36.000us         0.20%       2.659ms     132.950us       0.000us         0.00%     619.000us      30.950us            20  \n",
      "                           aten::_batch_norm_impl_index         0.01%      77.000us         0.20%       2.623ms     131.150us       0.000us         0.00%     619.000us      30.950us            20  \n",
      "                                 aten::cudnn_batch_norm         0.06%     735.000us         0.19%       2.546ms     127.300us     619.000us        14.28%     619.000us      30.950us            20  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.318s\n",
      "Self CUDA time total: 4.334ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
