{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glai/anaconda3/envs/subset/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload  \n",
    "%autoreload 2 \n",
    "import datasets\n",
    "from subset_active_learning.subset_selection import select, preprocess, compare\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: sst/default\n",
      "Reusing dataset sst (/home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n",
      "100%|██████████| 3/3 [00:00<00:00, 181.29it/s]\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-7b23d5d1250b3cef.arrow\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-6a94e7b0eb5aeeeb.arrow\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-f1806eefe95f0de4.arrow\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-e283858a38c31b48.arrow\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-39bfe2cb0f239a41.arrow\n",
      "Loading cached processed dataset at /home/glai/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-a9c205acb85f354d.arrow\n"
     ]
    }
   ],
   "source": [
    "processed_ds = preprocess.preprocess_sst2(\"google/electra-small-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select_subset(ds, seed, size):\n",
    "    np.random.seed(seed)\n",
    "    selected_indices = np.random.choice(len(ds), replace=False, size=size)\n",
    "    return ds.select(selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Seed set as 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/glai/dev/subset-active-learning/scripts/correlation/wandb/run-20221009_204614-j2l6grxx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/johnny-gary/subset-search-gpu-opt/runs/j2l6grxx\" target=\"_blank\">stellar-sponge-56</a></strong> to <a href=\"https://wandb.ai/johnny-gary/subset-search-gpu-opt\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch: 11, Avg batch loss: 0.00:   2%|▏         | 145/6000 [00:39<26:33,  3.67it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m comparison_run \u001b[38;5;241m=\u001b[39m compare\u001b[38;5;241m.\u001b[39mComparisonRun(train_ds \u001b[38;5;241m=\u001b[39m random_select_subset(ds\u001b[38;5;241m=\u001b[39mprocessed_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], seed\u001b[38;5;241m=\u001b[39mSEED, size\u001b[38;5;241m=\u001b[39mTRAIN_SIZE), \\\n\u001b[1;32m      4\u001b[0m                                         valid_ds \u001b[38;5;241m=\u001b[39m processed_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m], \\\n\u001b[1;32m      5\u001b[0m                                         test_ds \u001b[38;5;241m=\u001b[39m processed_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m], \\\n\u001b[1;32m      6\u001b[0m                                         seed \u001b[38;5;241m=\u001b[39m SEED)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m MODEL_CARD \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-large\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/electra-small-discriminator\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mcomparison_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwandb_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mMODEL_CARD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcorrelation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_size-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTRAIN_SIZE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSubsetTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_card\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_CARD\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/subset-active-learning/subset_active_learning/subset_selection/compare.py:151\u001b[0m, in \u001b[0;36mComparisonRun.one_run\u001b[0;34m(self, wandb_tags, config, num_workers, use_custom_subset_trainer)\u001b[0m\n\u001b[1;32m    135\u001b[0m subset_trainer \u001b[39m=\u001b[39m (\n\u001b[1;32m    136\u001b[0m     CustomSubsetTrainer(\n\u001b[1;32m    137\u001b[0m         params\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    150\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 151\u001b[0m subset_trainer\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m    152\u001b[0m     subset\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_ds, calculate_test_accuracy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mrun_time\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mround\u001b[39m(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time, \u001b[39m2\u001b[39m)})\n\u001b[1;32m    155\u001b[0m wandb_run\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/dev/subset-active-learning/subset_active_learning/subset_selection/select.py:44\u001b[0m, in \u001b[0;36mSubsetTrainer.train\u001b[0;34m(self, subset, calculate_test_accuracy, save_path)\u001b[0m\n\u001b[1;32m     42\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mmodel_card, num_labels\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mnum_labels)\n\u001b[1;32m     43\u001b[0m model\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 44\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(model, subset)\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m calculate_test_accuracy: \u001b[39m# evaluate test accuracy\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     test_eval_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluate(model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataloader)\n",
      "File \u001b[0;32m~/dev/subset-active-learning/subset_active_learning/subset_selection/select.py:88\u001b[0m, in \u001b[0;36mSubsetTrainer._train\u001b[0;34m(self, model, train_dataset, tolerance)\u001b[0m\n\u001b[1;32m     86\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     87\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 88\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mcpu()\n\u001b[1;32m     89\u001b[0m wandb\u001b[39m.\u001b[39mlog({\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m : loss})\n\u001b[1;32m     90\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mmax_grad_norm)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for TRAIN_SIZE in (100, 300, 500):\n",
    "    for SEED in range(42, 62):\n",
    "        comparison_run = compare.ComparisonRun(train_ds = random_select_subset(ds=processed_ds[\"train\"], seed=SEED, size=TRAIN_SIZE), \\\n",
    "                                                valid_ds = processed_ds[\"validation\"], \\\n",
    "                                                test_ds = processed_ds[\"test\"], \\\n",
    "                                                seed = SEED)\n",
    "        for MODEL_CARD in (\"roberta-large\", \"google/electra-small-discriminator\"):\n",
    "            comparison_run.one_run(wandb_tags=[MODEL_CARD, \"correlation\", f\"train_size-{TRAIN_SIZE}\"], config=select.SubsetTrainingArguments(model_card=MODEL_CARD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('subset')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93a8110c327b3f25735ecf324002c5782191dd6b384b2003081090d3bf4c3d32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
